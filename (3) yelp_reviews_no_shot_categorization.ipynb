{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyNGJ72jKhFSta7qpWzcwlmI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HKeriMdDAt9b","executionInfo":{"status":"ok","timestamp":1732990131228,"user_tz":360,"elapsed":777,"user":{"displayName":"Soumik Mukherjee","userId":"11504493022654908098"}},"outputId":"477328f3-19c0-4290-8982-a098982babf2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install pyspellchecker\n","!pip install py-readability-metrics\n","!pip install textstat\n","!pip install pyarrow\n","!pip install transformers\n","!pip install tqdm\n","!pip install datasets\n","!pip install tensorflow\n","!pip install torch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TJkAUi4EAy5_","executionInfo":{"status":"ok","timestamp":1732990154963,"user_tz":360,"elapsed":23393,"user":{"displayName":"Soumik Mukherjee","userId":"11504493022654908098"}},"outputId":"9c2f6eb4-1eab-4af6-f7ea-15db69214505"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyspellchecker in /usr/local/lib/python3.10/dist-packages (0.8.1)\n","Requirement already satisfied: py-readability-metrics in /usr/local/lib/python3.10/dist-packages (1.4.5)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from py-readability-metrics) (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->py-readability-metrics) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->py-readability-metrics) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->py-readability-metrics) (2024.9.11)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->py-readability-metrics) (4.66.6)\n","Requirement already satisfied: textstat in /usr/local/lib/python3.10/dist-packages (0.7.4)\n","Requirement already satisfied: pyphen in /usr/local/lib/python3.10/dist-packages (from textstat) (0.17.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from textstat) (75.1.0)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (17.0.0)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.26.4)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.0)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"]}]},{"cell_type":"code","source":["import os\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","import tensorflow as tf\n","import torch\n","\n","import textstat\n","from sklearn.feature_extraction.text import CountVectorizer\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","from nltk.tokenize import sent_tokenize\n","from spellchecker import SpellChecker\n","from readability import Readability\n","\n","from transformers import pipeline\n","from transformers import AutoTokenizer\n","from transformers import AutoModelForSequenceClassification\n","from transformers import Trainer, TrainingArguments\n","from transformers import TFAutoModelForSequenceClassification\n","\n","from datasets import Dataset\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","import gc\n","from tqdm import tqdm\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xZnnRewcAzxa","executionInfo":{"status":"ok","timestamp":1732990162392,"user_tz":360,"elapsed":7511,"user":{"displayName":"Soumik Mukherjee","userId":"11504493022654908098"}},"outputId":"ccce2aae-de21-4554-a321-c146dce33895"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":["## read yelp_dataset_for_model.csv\n","chunk_size = 100000\n","\n","# Initialize an empty DataFrame to concatenate chunks\n","yelp_data_full = pd.DataFrame()\n","\n","# Read CSV in chunks\n","with pd.read_csv('/content/drive/MyDrive/Code + Data/yelp_dataset_for_model_final.csv', chunksize=chunk_size) as reader:\n","    for i, chunk in enumerate(reader):\n","        yelp_data_full = pd.concat([yelp_data_full, chunk], ignore_index=True)\n","        del chunk\n","        gc.collect()\n","\n","        if (i + 1) % 5 == 0:\n","            print(f'Progress: {(i + 1) * chunk_size} rows processed')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mrmOeQEdA2Bf","executionInfo":{"status":"ok","timestamp":1732990190446,"user_tz":360,"elapsed":28060,"user":{"displayName":"Soumik Mukherjee","userId":"11504493022654908098"}},"outputId":"03e1378e-8146-4e87-effa-690bc69dbfef"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Progress: 500000 rows processed\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-37d500df032f>:9: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n","  for i, chunk in enumerate(reader):\n","<ipython-input-4-37d500df032f>:9: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n","  for i, chunk in enumerate(reader):\n"]},{"output_type":"stream","name":"stdout","text":["Progress: 1000000 rows processed\n","Progress: 1500000 rows processed\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-4-37d500df032f>:9: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n","  for i, chunk in enumerate(reader):\n"]}]},{"cell_type":"code","source":["print(len(yelp_data_full))\n","yelp_data = yelp_data_full\n","del yelp_data_full"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hvOzJ7SABoRc","executionInfo":{"status":"ok","timestamp":1732990190446,"user_tz":360,"elapsed":6,"user":{"displayName":"Soumik Mukherjee","userId":"11504493022654908098"}},"outputId":"cbc224f1-5cda-4062-de56-4fb1918e5cba"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["1872289\n"]}]},{"cell_type":"code","source":["yelp_data.drop('review_type', axis=1, inplace=True)"],"metadata":{"id":"GdW3lgVyCMa6","executionInfo":{"status":"ok","timestamp":1732990190699,"user_tz":360,"elapsed":256,"user":{"displayName":"Soumik Mukherjee","userId":"11504493022654908098"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["print(yelp_data.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kog2pep7DyaH","executionInfo":{"status":"ok","timestamp":1732990190901,"user_tz":360,"elapsed":204,"user":{"displayName":"Soumik Mukherjee","userId":"11504493022654908098"}},"outputId":"d5021e77-c3f9-45c6-f064-64a6e977a640"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['review_id', 'user_id', 'business_id', 'stars_reviewer', 'useful',\n","       'text', 'name', 'postal_code', 'stars_business', 'categories',\n","       'total_reviews_for_business', 'helpful', 'num_sentences',\n","       'num_characters', 'num_words'],\n","      dtype='object')\n"]}]},{"cell_type":"code","source":["print(yelp_data.isnull().sum())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TvgtgMvsBpna","executionInfo":{"status":"ok","timestamp":1732990191442,"user_tz":360,"elapsed":157,"user":{"displayName":"Soumik Mukherjee","userId":"11504493022654908098"}},"outputId":"b608ec4d-6e09-4f85-c3f3-e539453b7d25"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["review_id                     0\n","user_id                       0\n","business_id                   0\n","stars_reviewer                0\n","useful                        0\n","text                          0\n","name                          0\n","postal_code                   0\n","stars_business                0\n","categories                    0\n","total_reviews_for_business    0\n","helpful                       0\n","num_sentences                 0\n","num_characters                0\n","num_words                     0\n","dtype: int64\n"]}]},{"cell_type":"code","source":["print(yelp_data.columns)\n","yelp_data['useful'] = pd.to_numeric(yelp_data['useful'], errors='coerce')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iwISTiXOBrEx","executionInfo":{"status":"ok","timestamp":1732990191443,"user_tz":360,"elapsed":4,"user":{"displayName":"Soumik Mukherjee","userId":"11504493022654908098"}},"outputId":"e24becbd-c1c1-4f18-c57a-8310116c24f4"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['review_id', 'user_id', 'business_id', 'stars_reviewer', 'useful',\n","       'text', 'name', 'postal_code', 'stars_business', 'categories',\n","       'total_reviews_for_business', 'helpful', 'num_sentences',\n","       'num_characters', 'num_words'],\n","      dtype='object')\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","import torch\n","\n","# Load model and tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-mnli\")\n","model = AutoModelForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\").to(\"cuda\")\n","model.eval()  # Set model to evaluation mode\n","\n","# Define the labels and the corresponding hypotheses\n","labels = [\"regular\", \"comparative\", \"suggestive\"]\n","\n","# Example review\n","review_test = \"This is the phone you should buy.\"\n","\n","# Generate hypotheses based on labels\n","hypotheses = [f\"This review is {label}.\" for label in labels]\n","\n","# Tokenize the premise (review) and each hypothesis\n","premise = review_test  # The input review is the premise\n","tokenized_inputs = [\n","    tokenizer(\n","        premise,\n","        hypothesis,\n","        padding=True,\n","        truncation=True,\n","        max_length=256,\n","        return_tensors=\"pt\"\n","    ).to(\"cuda\")\n","    for hypothesis in hypotheses\n","]\n","\n","# Perform inference for each hypothesis\n","with torch.no_grad():\n","    logits = [model(**inputs).logits for inputs in tokenized_inputs]\n","\n","entailment_scores = torch.stack([logit[:, 2] for logit in logits]).squeeze()\n","\n","# Find the label with the highest entailment score\n","predicted_index = torch.argmax(entailment_scores).item()\n","predicted_label = labels[predicted_index]\n","\n","print(f\"Predicted label: {predicted_label}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LcE9Tx6eLIMy","executionInfo":{"status":"ok","timestamp":1732990194436,"user_tz":360,"elapsed":2996,"user":{"displayName":"Soumik Mukherjee","userId":"11504493022654908098"}},"outputId":"4da518a2-f82b-4e14-bf91-4394389e5210"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Predicted label: suggestive\n"]}]},{"cell_type":"code","source":["\n","# # classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=0)\n","\n","# tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-mnli\")\n","# model = AutoModelForSequenceClassification.from_pretrained(\"facebook/bart-large-mnli\").to(\"cuda\")\n","# model.eval()  # Set model to evaluation mode\n","\n","# ## pros of facebook/bart:\n","# # fine-tuned on natural language and determining relationships between text and categories.\n","# ## does not require labeled data\n","# ### exposed via Hugging Face pipeline\n","\n","# labels = [\"regular\", \"comparative\", \"suggestive\"]\n","\n","# # review_test = \"This phone is better than the last model I had.\"\n","# review_test = \"This is the phone you should buy.\"\n","# inputs = tokenizer(\n","#     review_test,\n","#     padding=True,\n","#     truncation=True,\n","#     max_length=256,\n","#     return_tensors=\"pt\"\n","# ).to(\"cuda\")\n","\n","# # Run inference\n","# with torch.no_grad():\n","#     logits = model(**inputs).logits\n","\n","# # Get the predicted label index\n","# predicted_index = torch.argmax(logits, axis=1).item()\n","\n","# # Map the index to the label name\n","# predicted_label = labels[predicted_index]\n","\n","# print(predicted_label)"],"metadata":{"id":"ewR1fuKIByJM","executionInfo":{"status":"ok","timestamp":1732989596812,"user_tz":360,"elapsed":5,"user":{"displayName":"Soumik Mukherjee","userId":"11504493022654908098"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["Categorize the reviews using no-shot"],"metadata":{"id":"JApdGiZYB2KS"}},{"cell_type":"code","source":["# BATCH_SIZE = 256\n","\n","# MAX_LENGTH = 256  # Truncate to 256 tokens\n","\n","# # Prepare a list to store the predicted labels\n","# predicted_labels = []\n","\n","# # Process the dataset in batches\n","# for i in tqdm(range(0, len(yelp_data), BATCH_SIZE), desc=\"Categorizing Reviews\"):\n","#     # Get a batch of reviews\n","#     batch_reviews = yelp_data['text'][i:i + BATCH_SIZE].tolist()\n","\n","#     # Tokenize the batch\n","#     inputs = tokenizer(\n","#         batch_reviews,\n","#         padding=True,\n","#         truncation=True,\n","#         max_length=MAX_LENGTH,\n","#         return_tensors=\"pt\"\n","#     ).to(\"cuda\")\n","\n","#     # Perform inference without gradients\n","#     with torch.no_grad():\n","#         logits = model(**inputs).logits\n","\n","#     # Get the predicted label indices\n","#     batch_predicted_indices = torch.argmax(logits, axis=1).cpu().numpy()\n","\n","#     # Map indices to label names\n","#     batch_predicted_labels = [labels[idx] for idx in batch_predicted_indices]\n","\n","#     # Append the results to the list\n","#     predicted_labels.extend(batch_predicted_labels)\n","\n","# # Add the predicted labels to the DataFrame\n","# yelp_data['review_type'] = predicted_labels\n","\n","\n","\n","labels = [\"regular\", \"comparative\", \"suggestive\"]\n","\n","# Parameters\n","BATCH_SIZE = 312  # Adjust this based on available memory\n","MAX_LENGTH = 100  # Truncate to 100 tokens\n","\n","# Prepare a list to store the predicted labels\n","predicted_labels = []\n","\n","# Process the dataset in batches\n","for i in tqdm(range(0, len(yelp_data), BATCH_SIZE), desc=\"Categorizing Reviews\"):\n","    # Get a batch of reviews\n","    batch_reviews = yelp_data['text'][i:i + BATCH_SIZE].tolist()\n","\n","    # Generate hypotheses for each review and flatten them\n","    hypotheses = [[f\"This review is {label}.\" for label in labels] for _ in batch_reviews]\n","    hypotheses = [item for sublist in hypotheses for item in sublist]\n","\n","    # Repeat each review for all hypotheses\n","    premises = [review for review in batch_reviews for _ in labels]\n","\n","    # Tokenize the batch of premise-hypothesis pairs\n","    inputs = tokenizer(\n","        premises,\n","        hypotheses,\n","        padding=True,\n","        truncation=True,\n","        max_length=MAX_LENGTH,\n","        return_tensors=\"pt\"\n","    ).to(\"cuda\")\n","\n","    # Perform inference without gradients\n","    with torch.no_grad():\n","        logits = model(**inputs).logits\n","\n","    # Reshape logits to match batch size and number of labels\n","    entailment_scores = logits[:, 2].view(len(batch_reviews), len(labels))\n","\n","    # Get the predicted label index for each review\n","    batch_predicted_indices = torch.argmax(entailment_scores, axis=1).cpu().numpy()\n","\n","    # Map indices to label names\n","    batch_predicted_labels = [labels[idx] for idx in batch_predicted_indices]\n","\n","    # Append the results to the list\n","    predicted_labels.extend(batch_predicted_labels)\n","\n","# Add the predicted labels to the DataFrame\n","yelp_data['review_type'] = predicted_labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wBs3vBvNB5eA","executionInfo":{"status":"ok","timestamp":1733013768035,"user_tz":360,"elapsed":23573606,"user":{"displayName":"Soumik Mukherjee","userId":"11504493022654908098"}},"outputId":"8d4b4d0f-20b2-4c34-9eff-3d62a1986d38"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["Categorizing Reviews: 100%|██████████| 6001/6001 [6:32:53<00:00,  3.93s/it]\n"]}]},{"cell_type":"code","source":["print(yelp_data.shape)\n","print(yelp_data.head())\n","print(yelp_data.columns)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KPj93u2tB7cM","executionInfo":{"status":"ok","timestamp":1733013768321,"user_tz":360,"elapsed":5,"user":{"displayName":"Soumik Mukherjee","userId":"11504493022654908098"}},"outputId":"ba135ceb-d87c-4ec5-abda-bc45b554fc18"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["(1872289, 16)\n","                review_id                 user_id             business_id  \\\n","0  6AxgBCNX_PNTOxmbRSwcKQ  r3zeYsv1XFBRA4dJpL78cw  gmjsEdUsKpj9Xxu6pdjH0g   \n","1  pUycOfUwM8vqX7KjRRhUEA  59MxRhNVhU9MYndMkz0wtw  gebiRewfieSdtt17PTW6Zg   \n","2  l3Wk_mvAog6XANIuGQ9C7Q  ZbqSHbgCjzVAqaa7NKWn5A  EQ-TZ2eeD_E0BHuvoaeG5Q   \n","3  XW_LfMv0fV21l9c6xQd_lw  9OAtfnWag-ajVxRbUTGIyg  lj-E32x9_FA7GmUrBGBEWg   \n","4  8JFGBuHMoiNDyfcxuWNtrA  smOvOajNG0lS4Pq7d8g4JQ  RZtGWDLCAtuipwaZ-UfjmQ   \n","\n","   stars_reviewer  useful                                               text  \\\n","0               5       0  Loved this tour! I grabbed a groupon and the p...   \n","1               3       0  Had a party of 6 here for hibachi. Our waitres...   \n","2               4       0  Locals recommended Milktooth, and it's an amaz...   \n","3               4       0  Love going here for happy hour or dinner!  Gre...   \n","4               4       0  Good food--loved the gnocchi with marinara\\nth...   \n","\n","                              name postal_code  stars_business  \\\n","0       The Voodoo Bone Lady Tours       70170             4.5   \n","1  Hibachi Steak House & Sushi Bar       93101             3.5   \n","2                        Milktooth       46203             4.0   \n","3              Brio Italian Grille       63131             3.5   \n","4                        LaScala's       19106             3.5   \n","\n","                                          categories  \\\n","0  Supernatural Readings, Tours, Hotels & Travel,...   \n","1     Steakhouses, Sushi Bars, Restaurants, Japanese   \n","2  Beer, Wine & Spirits, Cafes, Coffee & Tea, Res...   \n","3  Bars, Pizza, Nightlife, Cocktail Bars, Italian...   \n","4                 Pizza, Restaurants, Italian, Salad   \n","\n","   total_reviews_for_business  helpful  num_sentences  num_characters  \\\n","0                         366      0.0              8             804   \n","1                         502      0.0              6             524   \n","2                        1421      0.0              2             119   \n","3                         404      0.0              5             242   \n","4                         380      0.0              1             175   \n","\n","   num_words  review_type  \n","0        152  comparative  \n","1         97  comparative  \n","2         19   suggestive  \n","3         42  comparative  \n","4         31   suggestive  \n","Index(['review_id', 'user_id', 'business_id', 'stars_reviewer', 'useful',\n","       'text', 'name', 'postal_code', 'stars_business', 'categories',\n","       'total_reviews_for_business', 'helpful', 'num_sentences',\n","       'num_characters', 'num_words', 'review_type'],\n","      dtype='object')\n"]}]},{"cell_type":"code","source":["# write review_type to csv\n","\n","yelp_data.to_csv(\"/content/drive/MyDrive/Code + Data/yelp_dataset_for_model_no_shot_final.csv\", index=False)"],"metadata":{"id":"3RUaiyrAB9vG","executionInfo":{"status":"ok","timestamp":1733013808906,"user_tz":360,"elapsed":40589,"user":{"displayName":"Soumik Mukherjee","userId":"11504493022654908098"}}},"execution_count":13,"outputs":[]}]}